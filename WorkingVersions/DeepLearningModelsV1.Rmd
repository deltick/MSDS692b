---
title: "DeepLearningModels"
author: "John Tamer"
date: "1/30/2021"
output:
  slidy_presentation: default
  powerpoint_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r echo=FALSE, warning=FALSE}
library (readr)
library(tsibble)
library(tsibbledata)
library(fabletools)
library(fable)
library(dplyr)
library(reshape)
library(feasts)
library(timetk)
library(tidyverse)
library(ggplot2)
library(anomalize)
library(aTSA)
library(tsbox)
library(tsoutliers)
library(tidyverse)
library(tidyquant)
library(anomalize)
library(tseries)
library(forecast)
library(prophet)
library(fable.prophet)

```

## Read In Preprocessed Data


```{r pressure, echo=FALSE}
urlfile="https://raw.githubusercontent.com/deltick/MSDS692b/main/Data/USBPTS.csv"

inputTS<-read_csv(url(urlfile))


# inputSel2 <- inputTS %>% select(xDate, "Southwest Border")
# inputSel2 <- dplyr::rename(inputSel2, SWB = "Southwest Border")
# inputMelt2 <- melt(as.data.frame(inputSel2), id="xDate")
# 
# inputMelt2 <- inputMelt2 %>%
#   mutate(Month = yearmonth(xDate)) %>%
#   as_tsibble(index = Month)
# 
# inputMelt2 <- select(inputMelt2, -xDate)
# 
# inputTsb2 <- as_tsibble(inputMelt2, index=Month, key=variable)
# inputTsb2 %>% autoplot()
# 
# swb <- inputTsb2
# 
# swb.ts <- ts(swb$value, start=c(2000, 01), frequency=12)
# #swbWindow.ts <- window(x.ts, start=c(2008, 1), end=c(2019, 4))
# 
# swbWindow.ts <- swb.ts 
# 
# autoplot(swbWindow.ts)

```
## Fable Package Modeling






## ModelTime and TimeTK Packages

```{r}
interactive <- FALSE

t1 <- select(inputTS, xDate, "Southwest Border")

t1 <- dplyr::rename(t1, date=xDate)
t1 <- dplyr::rename(t1, value="Southwest Border")

t1 %>%
  plot_time_series(date, value, .interactive = interactive, .x_lab="Year", .y_lab="Encounters", .title="Southwest Border Encounters")

```


```{r}
# m750 <- t1
# 
# splits <- initial_time_split(m750, prop = 0.9)
# 
# model_fit_arima_no_boost <- arima_reg() %>%
#   set_engine(engine = "auto_arima") %>%
#   fit(value ~ date, data = training(splits))
# 
# (model_fit_arima_no_boost)
# 
# model_fit_arima_boosted <- arima_boost(
#   min_n = 2,
#   learn_rate = 0.015
# ) %>%
#   set_engine(engine = "auto_arima_xgboost") %>%
#   fit(value ~ date + as.numeric(date) + factor(month(date, label = TRUE), ordered = F),
#       data = training(splits))
# 
# model_fit_ets <- exp_smoothing() %>%
#   set_engine(engine = "ets") %>%
#   fit(value ~ date, data = training(splits))
# 
# model_fit_prophet <- prophet_reg() %>%
#   set_engine(engine = "prophet") %>%
#   fit(value ~ date, data = training(splits))
# 
# model_fit_lm <- linear_reg() %>%
#   set_engine("lm") %>%
#   fit(value ~ as.numeric(date) + factor(month(date, label = TRUE), ordered = FALSE),
#       data = training(splits))
# 
# 
# model_spec_mars <- mars(mode = "regression") %>%
#   set_engine("earth") 
# recipe_spec <- recipe(value ~ date, data = training(splits)) %>%
#   step_date(date, features = "month", ordinal = FALSE) %>%
#   step_mutate(date_num = as.numeric(date)) %>%
#   step_normalize(date_num) %>%
#   step_rm(date)
# 
# wflw_fit_mars <- workflow() %>%
#   add_recipe(recipe_spec) %>%
#   add_model(model_spec_mars) %>%
#   fit(training(splits))
# 
# 
# models_tbl <- modeltime_table(
#   model_fit_arima_no_boost,
#   model_fit_arima_boosted,
#   model_fit_ets,
#   model_fit_prophet,
#   model_fit_lm,
#   wflw_fit_mars
# )
# models_tbl
# 
# calibration_tbl <- models_tbl %>%
#   modeltime_calibrate(new_data = testing(splits))
# calibration_tbl
# 
# 
# calibration_tbl %>%
#   modeltime_forecast(
#     new_data    = testing(splits),
#     actual_data = m750
#   ) %>%
#   plot_modeltime_forecast(
#     .legend_max_width = 25, # For mobile screens
#     .interactive      = interactive
#   )
# 
# 
# calibration_tbl %>%
#   modeltime_accuracy() %>%
#   table_modeltime_accuracy(
#     .interactive = interactive
#   )
# 
# 
# refit_tbl <- calibration_tbl %>%
#   modeltime_refit(data = m750)
# refit_tbl %>%
#   modeltime_forecast(h = "3 years", actual_data = m750) %>%
#   plot_modeltime_forecast(
#     .legend_max_width = 25, # For mobile screens
#     .interactive      = interactive
#   )
# 
# 

```
## Fable Residual Diagnostics

```{r}
# library(feasts)
# fit %>%
#   select(arima) %>%
#   gg_tsresiduals()
# 
# fit %>%
#   select(arima) %>%
#   glance
# 
# fit %>%
#   select(ets) %>%
#   gg_tsresiduals()
# 
# fit %>%
#   select(snaive) %>%
#   gg_tsresiduals()
# 
# fit %>%
#   select(lm1) %>%
#   gg_tsresiduals()
# 
# fit %>%
#   select(nn) %>%
#   gg_tsresiduals()
# 


```

```{r}
# gg_tsdisplay(
#   swbWindow.tsb,
#   y = value,
#   plot_type = c("auto", "partial", "season", "histogram", "scatter", "spectrum"),
#   lag_max = NULL
# )

```


```{r}
inputSel <- inputTS %>% select(xDate, "Southwest Border")
inputMelt <- melt(as.data.frame(inputSel), id="xDate") 
inputTsb <- as_tsibble(inputMelt, index=xDate, key=variable)
inputTsb %>% autoplot(value)

```




```{r}

#inputTsb <- inputTsb2 %>% select(-variable)

t1 <- inputSel

t1 <- dplyr::rename(t1, date=xDate)
t1 <- dplyr::rename(t1, value="Southwest Border")

t1TS <- ts(t1$value, start = c(2000, 1), frequency = 12)
t1TS %>% as_tsibble()

t1tb <- as_tsibble(t1TS)


train <- t1tb %>%
  filter(year(index) <= 2017)

# fit <- train %>% model(
#   prophet = prophet(value ~ index)
# )
# 
# fit
# 
# components(fit)
# 
# components(fit)  %>% autoplot()
# 
# fc <- fit %>%
#   forecast(h = "3 years")
# 
# fc %>% autoplot(t1tb)
# 
# fc %>% accuracy(t1tb)
# 


fit2 <- train %>% model(
  prophet = prophet(value ~ growth("linear") + season("year", type="additive"))
)

components(fit2) %>% autoplot()

fc2 <- fit2 %>%
  fabletools::forecast(h = "2 years")

fc2 %>% autoplot(t1tb) +
  ggtitle("Prophet Forecast")



fc2 %>% accuracy(t1tb)


```

```{r}
#### fable nnet model

fitnn <- train  %>%
  model(nn = NNETAR(box_cox(value, 0.15)))

fcnn <- fitnn %>% forecast(h = "2 years")

fcnn %>%
  autoplot(t1tb)

accuracy(fcnn, t1tb,  ##need to fix this
         measures = list(
           point_accuracy_measures,
           interval_accuracy_measures,
           distribution_accuracy_measures
         ))



```

```{r}
library(prophet)
library(readxl)


#df <- read_excel("C:/Users/JJT/Desktop/SWBAppsV2.xlsx")
df <- read_excel("C:/Users/JJT/Desktop/SWBv3.xlsx")
tail(df)

names(df) <- c('ds', 'y')    #, 'y2', 'y3') 


###################################################

m <- prophet(df)

future <- make_future_dataframe(m, periods=24)

forecast <- predict(m, future)
tail(forecast)

plot(m, forecast)

prophet_plot_components(m, forecast)

df.cv <- cross_validation(m, initial=240, period=30, horizon=12, units='days')
tail(df.cv)

plot_cross_validation_metric(df.cv, metric = 'mape')

```

